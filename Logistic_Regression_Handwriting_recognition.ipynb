{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD11 noté du 15/04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_extraction import *\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x230e0510a00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAAD4CAYAAAA6ht7UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAJLElEQVR4nO3dW4xdZRnG8f/jlFJbSwA5CG1jqyEkhKiYCR5INKGiVQn1wguaaOoh6RWKRoMlXHBrovGQaDQNVElEuEAaG4OUghJjotiDhdIDZVJLO7TaokaJJrTV14u9K8N0hrbvt2avb+15fkmzZ6+92vVm98m39qxvv+tTRGB2rt7QdgHWTQ6OpTg4luLgWIqDYylzBnmwuTo/5rFgkIe0Qi/z95ci4tLJ2wcanHks4D1aPshDWqHH46EXptruU5WlODiWUhQcSSskPSdpTNLapoqy+qWDI2kE+D7wUeAaYJWka5oqzOpWMuJcD4xFxP6IOA48CKxspiyrXUlwFgGHJjwf7297DUlrJG2VtPUErxQczmpSEhxNse20qfaIWBcRoxExeh7nFxzOalISnHFgyYTni4HDZeVYV5QEZwtwlaRlkuYCtwIbmynLape+chwRJyXdBmwCRoD1EbGrscqsakVTDhHxCPBIQ7VYh/jKsaU4OJbi4FiKg2MpDo6lODiW4uBYioNjKQ6OpTg4luLgWIqDYykOjqU4OJbi4FiKg2MpDo6lODiWUtLJuUTSryXtkbRL0u1NFmZ1K/nO8UngKxGxXdJCYJukzRGxu6HarGLpEScijkTE9v7PLwN7mKKT04ZTIzdWkrQUuA54aorX1gBrAOYxv4nDWQWKPxxLehPwM+BLEfHPya+7BXg4ld4f5zx6obk/Ih5upiTrgpLfqgTcC+yJiG81V5J1QcmIcwPwaeBGSTv6fz7WUF1WuZLe8d8y9a1ObBbwlWNLGeh9jrM2Hd7Rdgmv6yNXvqvtEgbOI46lODiW4uBYioNjKQ6OpTg4luLgWIqDYykOjqU4OJbi4FiKg2MpnZjkrN2gJ2FrmFT1iGMpDo6lODiW0kR7zIikP0r6RRMFWTc0MeLcTq+L02aR0r6qxcDHgXuaKce6onTE+Q5wB/Df8lKsS0oa8m4GjkbEtjPs5+Wjh1BpQ94tkg7QW6z+Rkk/mbyTe8eHU8ltTu6MiMURsZTeCsC/iohPNVaZVc3XcSylkbmqiHgSeLKJf8u6wSOOpQzt7HgNM8hnkp1Vz/y9pt8PjziW4uBYioNjKQ6OpTg4luLgWIqDYykOjqU4OJbi4FiKg2MpDo6lODiWoogY2MFG3zkv/rBpyUCO1YXZ8axB9qqPXDG2LSJGJ2/3iGMpDo6lODiWUtrJeaGkhyTt7S8j/b6mCrO6lX519LvAoxHxSUlzwau1zhbp4Ei6APgA8BmAiDgOHG+mLKtdyanqbcAx4Ef925zcI2nB5J0mtgAf++t/Cg5nNSkJzhzg3cAPIuI64F/A2sk7TWwBvvTNIwWHs5qUBGccGI+IU4vUP0QvSDYLlPSO/xk4JOnq/qblwO5GqrLqlf5W9QXg/v5vVPuBz5aXZF1QFJyI2AGcNo9hw68TLcDDPGGZkXk/mp4Y9ZSDpTg4luLgWIqDYykOjqU4OJbi4FiKg2MpDo6lODiW4uBYioNjKQ6OpTg4luLgWIqDYykOjqWUtgB/WdIuSc9KekDSvKYKs7qVrMm5CPgiMBoR1wIj9FbKs1mg9FQ1B3ijpDn0+sYPl5dkXVDSV/Ui8E3gIHAE+EdEPDZ5P7cAD6eSU9VFwEpgGXAlsEDSaYu5ugV4OJWcqj4E/CkijkXECeBh4P3NlGW1KwnOQeC9kuZLEr0W4D3NlGW1K/mM8xS9Gw1sB3b2/611DdVllSttAb4buLuhWqxDfOXYUhwcS3FwLMXBsRQHx1IcHEtxcCzFwbEUB8dSHBxLcXAsxcGxFAfHUhwcS+nEDbLttQa5CvB0POJYioNjKQ6OpZwxOJLWSzoq6dkJ2y6WtFnS8/3Hi2a2TKvN2Yw4PwZWTNq2FngiIq4CnmCKJRVtuJ0xOBHxG+BvkzavBO7r/3wf8Ilmy7LaZT/jXB4RRwD6j5dNt6NbgIfTjH84dgvwcMoG5y+SrgDoPx5triTrgmxwNgKr+z+vBn7eTDnWFWfz6/gDwO+AqyWNS/o88HXgJknPAzf1n9sscsa5qohYNc1LyxuuxTrEV44txbPjDahhtvpM8ktwj0251SOOpTg4luLgWIqDYykOjqU4OJbi4FiKg2MpDo6lODiW4uBYioNjKZ2Y5OzCJGJGfuKxfR5xLMXBsRQHx1KyLcDfkLRX0jOSNki6cEartOpkW4A3A9dGxDuAfcCdDddllUu1AEfEYxFxsv/098DiGajNKtbEZ5zPAb+c7kW3AA+nouBIugs4Cdw/3T5uAR5O6QuAklYDNwPLIyKaK8m6IBUcSSuArwEfjIh/N1uSdUG2Bfh7wEJgs6Qdkn44w3VaZbItwPfOQC3WIb5ybCkDnR3f98z8Ts8I26s84liKg2MpDo6lODiW4uBYioNjKQ6OpTg4luLgWIqDYykOjqU4OJbi4FiKg2MpDo6lODiWkmoBnvDaVyWFpEtmpjyrVbYFGElL6K1VdbDhmqwDsqsAA3wbuANwT9UslPqMI+kW4MWIePos9v1/C/AJXskczip0zl9WlzQfuAv48NnsHxHrgHUAF+hij05DIjPivB1YBjwt6QC9O1Vsl/SWJguzup3ziBMRO5mwQH0/PKMR8VKDdVnlsi3ANsuVrAJ86vWljVVjneErx5bi4FiKg2MpDo6lODiW4uBYioNjKQ6OpTg4luLgWIqDYykOjqU4OJbi4FiKg2MpGuTCL5KOAS9M8/IlgL9F+Kpa3o+3RsSlkzcONDivR9LWiBhtu45a1P5++FRlKQ6OpdQUnHVtF1CZqt+Paj7jWLfUNOJYhzg4ltJ6cCStkPScpDFJa9uup22SDkja2V/rdGvb9Uyn1c84kkaAffTuszMObAFWRcTu1opqWVdaqtseca4HxiJif0QcBx4EVrZck52FtoOzCDg04fl4f9tsFsBjkrZJWtN2MdMZ6GKuU9AU22b79YEbIuKwpMvoreu+t39XtKq0PeKMA0smPF8MHG6plipExOH+41FgA73TeXXaDs4W4CpJyyTNBW4FNrZcU2skLZC08NTP9O56dtrdXmvQ6qkqIk5Kug3YBIwA6yNiV5s1texyYIMk6P3f/DQiHm23pKl5ysFS2j5VWUc5OJbi4FiKg2MpDo6lODiW4uBYyv8AXRxTDrpqrDcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52152, 128)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_list= Y.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2673"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_list.count(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.column_stack((X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(S, size = 0.1):\n",
    "    S_learn = []\n",
    "    S_test = []\n",
    "    for s in S:\n",
    "        if np.random.rand()< size:\n",
    "            S_test.append(s)\n",
    "        else:\n",
    "            S_learn.append(s)\n",
    "    return np.array(S_learn), np.array(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set =  split_train_test(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "(52152, 26)\n"
     ]
    }
   ],
   "source": [
    "def One_hot_encoding(y):\n",
    "    y_temp = np.zeros((y.shape[0],26))\n",
    "    for i in range(y.shape[0]):\n",
    "        y_temp[i, int(y[i])] =  1\n",
    "        \n",
    "    return y_temp\n",
    "\n",
    "#Test: o est la première lettre dans le dataset, c'est la 15ème lettre de l'alphabet donc elle est bien placée \n",
    "print(One_hot_encoding(Y)[0])\n",
    "print((One_hot_encoding(Y)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigm(v):\n",
    "    v2 = np.exp(-v)+1\n",
    "    v2 = 1/v2\n",
    "    return(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour compter le nbr d'erreur\n",
    "def nbr_error(u,S):\n",
    "    In = S[:,:-1]\n",
    "    Out = S[:,-1]\n",
    "    \n",
    "    u = u.reshape(26,129)\n",
    "    x = u[:,:-1]\n",
    "    b = u[:,-1]\n",
    "    \n",
    "    vect = In.dot(x.T) + b\n",
    "    vect = sigm(vect/100)\n",
    "    \n",
    "    \n",
    "    y_prediction =  np.array(vect.argmax(axis=1))\n",
    "    \n",
    "    \n",
    "    return (Out != y_prediction).sum()\n",
    "\n",
    "#fonction de calcul de la loss\n",
    "def loss(u,S):\n",
    "    In = S[:,:-1]\n",
    "    Out = S[:,-1]\n",
    "    \n",
    "    u = u.reshape(26,129)\n",
    "    x = u[:,:-1]\n",
    "    b = u[:,-1]\n",
    "    \n",
    "    vect = In.dot((x).T) + b\n",
    "    vect = sigm(vect/100)\n",
    "    y = One_hot_encoding(Out)\n",
    "    y_temp =  (y * vect).sum(axis=1)\n",
    "    \n",
    "    loss = -np.log(y_temp).sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52152, 128)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(v):\n",
    "    return(((np.exp(v).T)/(np.exp(v).sum(axis = 1))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95288.28656981965\n",
      "49564\n"
     ]
    }
   ],
   "source": [
    "u = np.random.randn(3354)\n",
    "print(loss(u,S))\n",
    "print(nbr_error(u,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3411.542071455311\n",
      "1 3209.529018530023\n",
      "2 3031.143185940572\n",
      "3 2872.695093887813\n",
      "4 2731.092172186244\n",
      "5 2603.7770171240227\n",
      "6 2488.647054150066\n",
      "7 2383.9749056454166\n",
      "8 2288.3378120552643\n",
      "9 2200.5585331534635\n",
      "10 2119.6573478322753\n",
      "11 2044.8136813004883\n",
      "12 1975.3356716745045\n",
      "13 1910.6360901355422\n",
      "14 1850.2132651595125\n",
      "15 1793.6359261785187\n",
      "16 1740.5311036961957\n",
      "17 1690.5744263319584\n",
      "18 1643.4822803180743\n",
      "19 1599.0054507216096\n",
      "20 1556.9239237069444\n",
      "21 1517.042610501202\n",
      "22 1479.187816665673\n",
      "23 1443.204301175672\n",
      "24 1408.9528177416983\n",
      "25 1376.3080447892548\n",
      "26 1345.156838937869\n",
      "27 1315.396747031797\n",
      "28 1286.934738302625\n",
      "29 1259.686115036327\n",
      "30 1233.5735757134742\n",
      "31 1208.526404014764\n",
      "32 1184.4797655048621\n",
      "33 1161.3740912976266\n",
      "34 1139.1545460859268\n",
      "35 1117.7705535213208\n",
      "36 1097.1753815529446\n",
      "37 1077.3257782043215\n",
      "38 1058.1816470138513\n",
      "39 1039.7057575811311\n",
      "40 1021.8634914806352\n",
      "41 1004.6226111314537\n",
      "42 987.9530572408142\n",
      "43 971.8267631473741\n",
      "44 956.2174908518998\n",
      "45 941.1006824592239\n",
      "46 926.4533262205628\n",
      "47 912.2538343156721\n",
      "48 898.481933328563\n",
      "49 885.1185652001623\n",
      "8950.549496023186\n",
      "33774\n"
     ]
    }
   ],
   "source": [
    "grad = grad_desc_n(loss, test_set, 3354, 50, step = 0.5, x_0 = None)\n",
    "\n",
    "u_solution = grad\n",
    "\n",
    "print(loss(u_solution,S))\n",
    "print(nbr_error(u_solution,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_n(f, epsilon = 10**(-6)):\n",
    "    def grad(x, param):\n",
    "        y = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            x_temp = np.array(x)\n",
    "            x_temp[i] += epsilon\n",
    "            x_temp2 = np.array(x)\n",
    "            x_temp2[i] -= epsilon\n",
    "            y[i] = (f(x_temp, param)-f(x_temp2, param))/(2*epsilon)\n",
    "        return y\n",
    "    return grad\n",
    "\n",
    "def grad_desc_n(f, param, dim, nb_iter, step = 0.01, x_0 = None):\n",
    "    if x_0 is None:\n",
    "        x_0 = np.random.randn(dim)\n",
    "    grad_f = grad_n(f)\n",
    "    x = x_0\n",
    "    for i in range(nb_iter):\n",
    "        dx = grad_f(x, param)*step\n",
    "        x -= dx\n",
    "        print(i, f(x,param))\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(T_vec, S):\n",
    "    \n",
    "    T1 = T_vec[:129*Nhidden]\n",
    "    #T1.shape : (1290,)\n",
    "    T2 = T_vec[129*Nhidden:]\n",
    "    #T2.shape : (286,)\n",
    "    U1 = T1[:128*Nhidden]\n",
    "    #U1.shape : (1280,) si Nhidden =10\n",
    "    U1 = U1.reshape(128, Nhidden)\n",
    "    #U1.shape : (128,Nhidden)\n",
    "    b1 = T1[128*Nhidden:]\n",
    "    #b1.shape : (Nhidden,)\n",
    "    U2 = T2[:Nhidden*26]\n",
    "    #U2.shape : (286,)\n",
    "    U2 = U2.reshape(Nhidden, 26)\n",
    "    #U2.shape : (Nhidden,26)\n",
    "    b2 = T2[Nhidden*26:]\n",
    "    #b2.shape(26,)\n",
    "    X = S[:,:-1]\n",
    "    out = softmax(RELU(X.dot(U1)+b1).dot(U2)+b2)\n",
    "    \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RELU(v):\n",
    "    return((1*(v>0))*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir de ce point je fais la descente de gradient pour le réseau avec une couche cachée de 10 neurones:\n",
    "Nhidden=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implémentation de la loss en utilisant output:\n",
    "#je fusionne les fonctions loss et output ensembles car sans cela le programme retourne toujours une erreur np.ndarray is not \n",
    "#callable \n",
    "def loss_output(T_vec,S):\n",
    "    \n",
    "    T1 = T_vec[:129*Nhidden]\n",
    "    #T1.shape : (1290,)\n",
    "    T2 = T_vec[129*Nhidden:]\n",
    "    #T2.shape : (286,)\n",
    "    U1 = T1[:128*Nhidden]\n",
    "    #U1.shape : (1280,) si Nhidden =10\n",
    "    U1 = U1.reshape(128, Nhidden)\n",
    "    #U1.shape : (128,Nhidden)\n",
    "    b1 = T1[128*Nhidden:]\n",
    "    #b1.shape : (Nhidden,)\n",
    "    U2 = T2[:Nhidden*26]\n",
    "    #U2.shape : (286,)\n",
    "    U2 = U2.reshape(Nhidden, 26)\n",
    "    #U2.shape : (Nhidden,26)\n",
    "    b2 = T2[Nhidden*26:]\n",
    "    #b2.shape(26,)\n",
    "    X = S[:,:-1]\n",
    "    Y = S[:,-1]\n",
    "    out = softmax((RELU((X.dot(U1)+b1)).dot(U2)+b2)/255)\n",
    "    out = out\n",
    "    y = One_hot_encoding(Y)\n",
    "    y_temp =  (y * out).sum(axis=1)\n",
    "    \n",
    "    \n",
    "    loss = -np.log(y_temp).sum()\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.58223761e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "1567483.697977284\n"
     ]
    }
   ],
   "source": [
    "#test avec T\n",
    "T = np.random.randn(129*Nhidden+(Nhidden+1)*26)\n",
    "print(loss_output(T,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbr_error_output(T_vec,S):\n",
    "    T1 = T_vec[:129*Nhidden]\n",
    "    #T1.shape : (1290,)\n",
    "    T2 = T_vec[129*Nhidden:]\n",
    "    #T2.shape : (286,)\n",
    "    U1 = T1[:128*Nhidden]\n",
    "    #U1.shape : (1280,) si Nhidden =10\n",
    "    U1 = U1.reshape(128, Nhidden)\n",
    "    #U1.shape : (128,Nhidden)\n",
    "    b1 = T1[128*Nhidden:]\n",
    "    #b1.shape : (Nhidden,)\n",
    "    U2 = T2[:Nhidden*26]\n",
    "    #U2.shape : (286,)\n",
    "    U2 = U2.reshape(Nhidden, 26)\n",
    "    #U2.shape : (Nhidden,26)\n",
    "    b2 = T2[Nhidden*26:]\n",
    "    #b2.shape(26,)\n",
    "    X = S[:,:-1]\n",
    "    Y = S[:,-1]\n",
    "    out = softmax(RELU((X.dot(U1/255)+b1)).dot(U2)+b2)\n",
    "    out = out/255\n",
    "    \n",
    "    y_prediction =  np.array(out.argmax(axis=1))\n",
    "    \n",
    "    \n",
    "    return (Y != y_prediction).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49922\n"
     ]
    }
   ],
   "source": [
    "print(nbr_error_output(T,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17018.276166929485\n",
      "1 16949.157543894144\n",
      "2 16828.92789040501\n",
      "3 16611.875986847263\n",
      "4 16254.645887477769\n",
      "5 15794.273949779854\n",
      "6 15425.395277111318\n",
      "7 15179.581756059015\n",
      "8 14953.170314044379\n",
      "9 14716.904889982612\n",
      "10 14458.733831706082\n",
      "11 14177.302722459364\n",
      "12 13882.03216017674\n",
      "13 13591.91051617576\n",
      "14 13321.194139032707\n",
      "15 13071.415607413739\n",
      "16 12837.637821340631\n",
      "17 12614.492126490893\n",
      "18 12398.689921786365\n",
      "19 12188.667434867964\n",
      "20 11985.86836612534\n",
      "21 11796.087161543468\n",
      "22 11658.72351396404\n",
      "23 11729.936640254211\n",
      "24 12728.237552084245\n",
      "25 11472.52515074751\n",
      "26 11424.042077333675\n",
      "27 11291.3652952226\n",
      "28 11776.682598845297\n",
      "29 10683.101782231548\n",
      "107773.13462684916\n",
      "47239\n"
     ]
    }
   ],
   "source": [
    "grad = grad_desc_n(loss_output, test_set, 1576, 30, step = 0.05, x_0 = None)\n",
    "\n",
    "u_solution = grad\n",
    "\n",
    "print(loss_output(u_solution,S))\n",
    "print(nbr_error_output(u_solution,S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
